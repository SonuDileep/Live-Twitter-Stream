package pa2;

import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Comparator;
import java.util.LinkedHashMap;
import java.util.stream.Collectors;
import org.apache.storm.Config;
import org.apache.storm.Constants;
import org.apache.storm.task.OutputCollector;
import org.apache.storm.task.TopologyContext;
import org.apache.storm.topology.OutputFieldsDeclarer;
import org.apache.storm.topology.base.BaseRichBolt;
import org.apache.storm.tuple.Fields;
import org.apache.storm.tuple.Tuple;
import org.apache.storm.tuple.Values;

public class CountBolt extends BaseRichBolt {

	Map<String, Item> counts = new HashMap<String, Item>();
	private OutputCollector collector;
	private double epsilon = 0.005;
	private double threshold = 0.006;
  	private Integer emitFrequency = 10;
	private int bucket_capacity = ( int ) ( 1 / epsilon );
	private int bucket = 1;
	private long items = 0;


	@Override
	public Map<String, Object> getComponentConfiguration() {
		Config conf = new Config();
		conf.put( Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, emitFrequency );
		return conf;
	}

	@Override
	public void execute(Tuple tuple, OutputCollector collector) {
		if ( tuple.getSourceComponent().equals( Constants.SYSTEM_COMPONENT_ID )
				&& tuple.getSourceStreamId()
						.equals( Constants.SYSTEM_TICK_STREAM_ID ) )
		{
					this.collector=collector
					int total = counts.size();
					counts.values().removeIf( value -> value.frequency < ( threshold
						- epsilon ) / total );
						int size = counts.size() > 100 ? 100 : counts.size();
						if ( size == 0 )
						{
							return;
						}
						Map<String, Item> output = sortMapDecending( counts, size );
						for ( Entry<String, Item> entry : output.entrySet() )
						{
							collector.emit( 
									new Values( entry.getKey(), entry.getValue().actual() ) );
						}
					
		} else
		{
			if ( ++items % bucket_capacity == 0 )
			{
				// process entire bucket and then run delete phase.
				delete();
				++bucket;
			}
			insert( tuple );
		}
	}

	/**
	 * insert the items to D updating the ones that exist or creating a
	 * new entry (e, 1, b - 1) <br>
	 * <br>
	 * e : current word <br>
	 * b : current bucket
	 * 
	 * @param tuple
	 */
	private void insert(Tuple tuple) {
		String s = tuple.getStringByField( "hash" );
		Item item = counts.get( s );
		if ( item == null )
		{
			item = new Item( bucket - 1 );
		}
		item.increment();
		counts.put( s, item );
	}

	/**
	 * items from the current D where f + d <= b <br>
	 * <br>
	 * f : frequency of word <br>
	 * d : delta value of b - 1 when seen <br>
	 * b : current bucket
	 */
	private void delete() {
		counts.values().removeIf( value -> value.deconstruct( bucket ) );
	}

	/**
	 * The top 100 true frequencies of e : f + delta <br>
	 * <br>
	 * f : frequency of word <br>
	 * d : delta value of b - 1 when seen <br>
	 * 
	 */

	private static <K, V extends Comparable<V>> Map<K, V> sortMapDecending(
			Map<K, V> map, int size) {
		return map.entrySet().stream()
				.sorted( Map.Entry
						.comparingByValue( Comparator.reverseOrder() ) )
				.limit( size )
				.collect( Collectors.toMap( Map.Entry::getKey,
						Map.Entry::getValue, (e1, e2) -> e1,
						LinkedHashMap::new ) );
	}

	

	/**
	 * Only emit those entries in data structure D, where f >= (s - e) / N
	 * <br>
	 * <br>
	 * f : frequency of word <br>
	 * s : threshold (between 0 - 1) <br>
	 * e : epsilon <br>
	 * N : total number of items in D data structure D <br>
	 * 
	 */


	/**
	 * 
	 * @author stock
	 *
	 */
	private final static class Item implements Comparable<Item> {

		private final int delta;
		private long frequency = 0L;

		private Item(int delta) {
			this.delta = delta;
		}

		private long actual() {
			return frequency + delta;
		}

		private void increment() {
			frequency++;
		}

		private boolean deconstruct(int currentBucket) {
			return frequency + delta <= currentBucket;
		}

		@Override
		public int compareTo(Item o) {
			return Long.compare( this.actual(), o.actual() );
		}

		@Override
		public String toString() {
			return "( " + frequency + ", " + delta + " )";
		}
	}

	@Override
	public void declareOutputFields(OutputFieldsDeclarer declarer) {
		declarer.declare( new Fields( "word", "count" ) );
	}


}
